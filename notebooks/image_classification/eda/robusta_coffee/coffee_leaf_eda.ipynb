{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exploratory Data Analysis: coffee leaf",
   "id": "8da2e194774c6b9d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "dataset_path = './dataset/Photos'\n",
    "image_files = [f for f in os.listdir(dataset_path) if f.lower().endswith(('.jpg', '.png'))]\n",
    "\n",
    "print(f\"Total images in dataset: {len(image_files)}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Check for images integrity\n",
    "The check for images integrity, will check for corrupt files, such as images that cannot be open.\n",
    "Then, it returns the corrupt file when found and remove this file from bytecode array."
   ],
   "id": "93fd996f829626f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "corrupted_images = []\n",
    "\n",
    "for img_file in image_files:\n",
    "    img_path = os.path.join(dataset_path, img_file)\n",
    "\n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            img.verify()\n",
    "    except (UnidentifiedImageError, IOError):\n",
    "        corrupted_images.append(img_file)\n",
    "\n",
    "if corrupted_images:\n",
    "    print(f\"Found {len(corrupted_images)} corrupted images:\")\n",
    "    for img in corrupted_images:\n",
    "        print(img)\n",
    "else:\n",
    "    print(\"No corrupted images found!\")\n",
    "\n",
    "for img_file in corrupted_images:\n",
    "    os.remove(os.path.join(dataset_path, img_file))\n",
    "    print(f\"Deleted corrupted file: {img_file}\")\n"
   ],
   "id": "8761b76b0f018104",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check for images saturation\n",
   "id": "f769548e8b2047b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_brightness(image):\n",
    "    return np.mean(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))  # Convert to grayscale & compute mean\n",
    "\n",
    "brightness_values = [compute_brightness(cv2.imread(os.path.join(dataset_path, img_file)))\n",
    "                     for img_file in image_files if cv2.imread(os.path.join(dataset_path, img_file)) is not None]\n",
    "\n",
    "plt.hist(brightness_values, bins=30, color='gray')\n",
    "plt.title(\"Brightness Distribution\")\n",
    "plt.xlabel(\"Brightness\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ],
   "id": "7a16c76b0b8f6961",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Check for blurry images",
   "id": "61e8404a2ebe2983"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def variance_of_laplacian(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()  # Compute Laplacian variance\n",
    "\n",
    "blur_scores = [variance_of_laplacian(cv2.imread(os.path.join(dataset_path, img_file), cv2.IMREAD_GRAYSCALE))\n",
    "               for img_file in image_files if cv2.imread(os.path.join(dataset_path, img_file)) is not None]\n",
    "\n",
    "plt.hist(blur_scores, bins=30, color='blue')\n",
    "plt.title(\"Blurriness Distribution\")\n",
    "plt.xlabel(\"Variance of Laplacian\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ],
   "id": "ba59833199bc93f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "means = {'R': [], 'G': [], 'B': []}\n",
    "\n",
    "for img_file in image_files:\n",
    "    img = cv2.imread(os.path.join(dataset_path, img_file))\n",
    "    if img is not None:\n",
    "        b, g, r = cv2.mean(img)[:3]  # Extract mean BGR values\n",
    "        means['B'].append(b)\n",
    "        means['G'].append(g)\n",
    "        means['R'].append(r)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for color in ['R', 'G', 'B']:\n",
    "    plt.hist(means[color], bins=30, alpha=0.6, label=color, color=color.lower())\n",
    "plt.title(\"Color Channel Intensity Distribution\")\n",
    "plt.xlabel(\"Intensity\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "230b98c61bb0ed3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Clustering similar images using K-MEANS",
   "id": "52fbd13afd226dba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def extract_color_histogram(image_path, bins=(8, 8, 8)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([img], [0, 1, 2], None, bins, [0, 256, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten()\n",
    "\n",
    "features = np.array([extract_color_histogram(os.path.join(dataset_path, img_file))\n",
    "                     for img_file in image_files if cv2.imread(os.path.join(dataset_path, img_file)) is not None])\n",
    "num_clusters = 2  # Change this based on expected groups\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "labels = kmeans.fit_predict(features)\n",
    "\n",
    "clustered_images = {i: [] for i in range(num_clusters)}\n",
    "for img_file, label in zip(image_files, labels):\n",
    "    clustered_images[label].append(img_file)\n",
    "\n",
    "# Print results\n",
    "for cluster, images in clustered_images.items():\n",
    "    print(f\"Cluster {cluster}: {len(images)} images\")\n"
   ],
   "id": "76fbdb8ec7db789a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Model training with SVC",
   "id": "26825ee4f32fa6fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "file_path = \"./dataset/RoCoLe-classes.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n"
   ],
   "id": "33a78e04e36db07d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
